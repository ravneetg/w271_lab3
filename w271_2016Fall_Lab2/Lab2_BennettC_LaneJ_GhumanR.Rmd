---
title: "Applied Regression and Time Series Analysis: Lab 2"
author: "Jeffrey Yau and Devesh Tiwari"
date: "October 25, 2016"
output: pdf_document
---

##Instructions:

*  **Due Date: 12/16/2016 (Friday)**
*  Late submission will not receive any credit.
*  Instructions must be followed strictly.
*  This lab can be completed in a group of up to 3 people. Each group only needs to make one submission.
*  Submit 2 files: (1) a report (in pdf format) detailing your analyses; (2) your R script or juypter notebook supporting all of your answers. Missing one of this files will result in an automatic 50% reduction in score.
*  Use only techniques and R libraries that are covered in this course.
*  If you use R libraries and/or functions to conduct hypothesis tests not covered in this course, you will have to explain why the function you use is appropriate for the hypothesis you are asked to test
*  Thoroughly analyze the given dataset or data series. Detect any anomalies in each of the variables.
*  Your report needs to include a comprehensive graphical analysis
*  Your analysis needs to be accompanied by detailed narrative. Just printing a bunch of graphs and econometric results will likely receive a very low score.
*  Your analysis needs to show that your models are valid (in statistical sense).
*  Your rationale of using certian metrics to choose models need to be provided. Explain the validity / pros / cons of the metric you use to choose your "best" model.
*  Your rationale of any decisions made in your modeling needs to be explained and supported with empirical evidence.
*  All the steps to arrive at your final model need to be shown and explained clearly.
*  All of the assumptions of your final model need to be thoroughly tested, explained, and shown to be valid. Don't just write something like, *"the plot looks reasonable", or "the plot looks good*, as different people interpret vague terms like "reasonable" or "good" differently.
*  Students are expected to act with regards to UC Berkeley Academic Integrity.


# Forecast Inflation-Adjusted Gas Price
During 2013 amid high gas prices, the Associated Press (AP) published an article about the U.S. inflation-adjusted price of gasoline and U.S. oil production. The article claims that there is "*evidence of no statistical correlation*" between oil production and gas prices. The data was not made publicly available, but comparable data was created using data from the Energy Information Administration. The workspace and data frame *gasOil.Rdata* contains the U.S. oil production (in millions of barrels of oil) and the inflation-adjusted average gas prices (in dollars) over the date range the article indicates.

You have three tasks for this exericse, and both tasks need the use of the data set *gasOil.Rdata*.

```{r}
library(dtplyr)
library(Hmisc)
library(astsa)
library(stargazer)
library(forecast)
library(readr)
library(reshape2)
library(car)
library(vars)
library(tseries)
load("gasOil.Rdata")
```


Task 1: Create a **SARIMA-type** model to forecast the inflation-adjusted gas prices, and use this model to forecast the inflation-adjusted gas price for the next two years.

#Exploratory Data Analysis

The price series is not stationary, as the time series has strong persistency and inconsistent variation.  In particular, the time series before 2005 shows a strong persistence while the time series after 2005 shows much greater variation.  Also, ACF does not seem to drop off.  The PACF seems to drop off after 2 lags, and the second lag seems to have a negative coefficient.  There are no sudden spikes in either ACF or PACF that would suggest a seasonal effect.


```{r}
describe(gasOil)
 runEDA = function(x,label,l = 50){
   par(mfrow=c(3,1))
   print(paste("Dickey Fuller Test:",adf.test(x)$p.value)
         )
   plot.ts(x, main = paste("Time Series Plot of",label),ylab= label)
   acf(x,main = paste("ACFPlot of",label),ylab = label,lag.max = l)
   pacf(x, main = paste("PACF Plot of",label),ylab = label,lag.max=l)

 }
 runEDA(gasOil$Price,"Price")


```


So let's take the first difference and run EDA again.  The differenced series does not show persistency, but there is still increased variance after 2005.  This is unlikely to be fixed by taking more differences, because the ADF test says that the series does not have any roots greater than |1|.  So I'm going to start the model building process here.

Note that in the differenced series the ACF drops off after 1 lag, but seems to reappear approximately every 6 lags and then lingers for 1 or 2 lags before dropping again.  This suggests a MA component with degree 1 and a seasonal MA component with period 6 and degree 2.  In the PACF graph, the correlation drops off after 2 lags, but then reappears approximately every 5 lags.  This suggest an AR component with degree 2 and seasonal AR component with period 5 and degree 1.

```{r}
diffPrice = diff(gasOil$Price,differences = 1)
runEDA(diffPrice, "Change in Price")
```

#Model Training 

So the general ballpark is SARIMA model with order (2,1,1) and seasonal order (1,1,1~2) and period 5~6.  To nail down the exact parameters, we will need to use the AIC:

```{r}
runFitDiagnoseModel = function(x1,o,s,holdout=0){
# 7. Backtesting and Out-of-Sample Forecasting
# Re-estimate the model holding out 10 observations
    original =x1[1:(length(x1)-holdout)] 

  fit <- arima(original, order=o,seasonal = s)


# Model Diagnostics: Residuals
  print(Box.test(fit$resid, type="Ljung-Box"))

  par(mfrow=c(2,2))
  plot(fit$resid, col="blue", main="Residual Series")
  hist(fit$resid, col="gray", main="Residuals")
  acf(fit$resid , main="ACF: Residual Series")
  pacf(fit$resid,main="PACF: Residual Series")

# Model Performance Evaluation: In-Sample Fit

  df <- data.frame(cbind(original,fitted(fit),fit$resid ))
  stargazer(df, type="text", title="Descriptive Stat", digits=1)
##########

# Plot the original and estimate series 
  par(mfrow=c(1,1))
  plot.ts(original, col="navy", 
          main=paste("Original vs ARIMA(",toString(o),"),(",toString(s), ") with Resdiauls"),
          ylab="Original and Estimated Values",
          lty=2,ylim=c(0,4))
  lines(fitted(fit),col="blue",xlab="",ylab="")

  leg.txt <- c("Original", "Estimated", "Residuals")
  legend("bottomleft", legend=leg.txt, lty=c(2,1,1), col=c("navy","blue","green"),
         bty='n', cex=1)

  lines(fit$resid,xlab="",ylab="",col="green",
          pch=1)
  mtext("Residuals", side=4, line=2,col="green")
  #--------------------------------------
if(holdout > 0){
  fit.fcast <- forecast.Arima(fit, h=holdout)

  par(mfrow=c(1,1),new=F)
  plot(fit.fcast,lty=0,
       main="Out-of-Sample Forecast",
     
       ylab="Original, Estimated, and Forecast Values")
  lines(fitted(fit), col="blue")
  lines(x1, col="navy", lty=2)
  leg.txt <- c("Original", "Fitted", "Forecast")
  legend("bottomleft", legend=leg.txt, lty=c(2,1,1),
         col=c("navy","blue","blue"), lwd=c(1,1,2),
         bty='n', cex=1)
  MSE = mean((fit.fcast$mean - tail(x1,holdout))^2)
  print(paste("MSE:",MSE))
}
return(fit)
}
```


Out of the four possible models, model2 [ARIMA (2,1,1),(1,1,1) period 6] has the lowest mean squared error using a holdout of 24.  Also, model1 [ARIMA (2,1,1),(1,1,1) period 5] has a lower AIC than model3 [ARIMA (2,1,1),(1,1,2) period 5].  Model4 [ARIMA (2,1,1),(1,1,2) period 6] returned an error and would not compile.

```{r}
model1=runFitDiagnoseModel(gasOil$Price,c(2,1,1),list(order = c(1,1,1), period=5),24)
```
```{r}
model2=runFitDiagnoseModel(gasOil$Price,c(2,1,1),list(order = c(1,1,1), period=6),24)

```

```{r}
model3=runFitDiagnoseModel(gasOil$Price,c(2,1,1),list(order = c(1,1,2), period=5),24)

```

Model 4 (SARIMA (2,1,1),(1,1,2) period 6) returned an error.  

```{r}
print(try({
model4=runFitDiagnoseModel(gasOil$Price,c(2,1,1),list(order = c(1,1,2), period=6),24)},silent=T
))
```

Further diagnostics show that the 2nd AR and first MA coefficients in non-seasonal component of model2 are not siginificantly different from 0.  This suggests trying to fit an ARIMA (1,1,0), (1,1,1) period 6 model.

```{r}
t( confint(model2) )

```
While the new model5 [ARIMA (1,1,0),(1,1,1)] has some improvment in the MSE, its AIC is higher than model2.  So we're going to stick with model2 for now.

```{r}
model5=runFitDiagnoseModel(gasOil$Price,c(1,1,0),list(order = c(1,1,1), period=6),24)
AIC(model2,model5)
```

The last step is to retrain the model on the entire data set and then forecast 2 years out.  

```{r}
modelSarima=runFitDiagnoseModel(gasOil$Price,c(2,1,1),list(order = c(1,1,1), period=6))
forecastSarima = forecast.Arima(modelSarima, h=24)
print(forecastSarima)

```


Task 2: Create a *multivariate* time series model that can be used to predict/forecast inflation-adjusted gas prices, and use this model to forecast the inflation-adjusted gas price for the next two years

```{r}
# Fitting a linear trend to the Gas Price Data
# Regress Price on time
summary(price.fit_lm <- lm(price.ts ~ time(price.ts)))
price.fit_lm$coeff
price.fit_lm$qr
price.fit_lm$fitted.values

# Fitting a linear trend to the Gas Production Data
# Regress Production on time
summary(production.fit_lm <- lm(production.ts ~ time(production.ts)))
production.fit_lm$coeff
production.fit_lm$qr
production.fit_lm$fitted.values

#Plot the regression lines for both Price and Production
par(mfrow=c(2,1))
plot(price.ts, col="blue", main="", xlab="Year", ylab="Gas Price")
title("Inflation-Adjusted Gas Prices")
abline(price.fit_lm) # add the fitted regression line to the plot

plot(production.ts, col="blue", main="", xlab="Year", ylab="Gas Production")
title("Inflation-Adjusted Gas Production")
abline(production.fit_lm) # add the fitted regression line to the plot

#Look at the first few records for both price and production
head(cbind(price.ts, production.ts))

#Evaluate Correlation between price and correlation
cor(price.ts, production.ts)

#Plot the price and production time series
par(mfrow=c(2,2))
plot.ts(price.ts); title("Time-Series Plot of Price")
plot.ts(production.ts); title("Time-Series Plot of Production")
ts.plot(ts(price.ts),ts(production.ts)); title("Time-Series Plot of Price and Production")
plot(price.ts,production.ts); title("Price vs Production")

# Show summary statistics, even though they might not be useful for a timeseries
summary(cbind(price.ts, production.ts))

#Plot the autocorrelation fuction and partial autocorrelation function for both price and production for 36 lags
par(mfrow=c(2,2))
acf(price.ts, main="", 36); title("ACF of Price")  
acf(production.ts, main="", 36); title("ACF of Production")
pacf(price.ts, main="", 36); title("PACF of Price")
pacf(production.ts, main="", 36); title("PACF of Production")

#More EDA on Price time series (plot, histogram, acf, and pacf)
par(mfrow=c(2,2))
plot.ts(price.ts)
hist(price.ts)
acf(price.ts)
pacf(price.ts)

#More EDA on Production time series (plot, histogram, acf, and pacf)
par(mfrow=c(2,2))
plot.ts(production.ts)
hist(production.ts)
acf(production.ts)
pacf(production.ts)

#Run the Augmented Dickey-Fuller Test to determine if Unit Root is present for price and production
adf.test(price.ts)
adf.test(production.ts)
#none of these tests fail to reject the null hypothesis that each of these series is unit root.

#Phillips-Ouliaris Cointegration Test
po.test(cbind(price.ts,production.ts))

#Aggregate into an annualized series
cbind(price.ts[1:12],production.ts[1:12])
cbind(aggregate(price.ts), aggregate(production.ts))
cbind(sum(price.ts[1:12]),sum(production.ts[1:12]))

tempx<-aggregate(price.ts); tempy<-aggregate(production.ts)
cbind(tempx[1],tempy[1]) # which is the same as sum(price.ts[1:12]) and sum(production.ts[1:12])

#Plot Aggregate annualized values for Price and Production
par(mfrow=c(1,1))
plot(as.vector(tempx), as.vector(tempy), xlab="Price", ylab="Production", col="blue")
title("Annual Price vs. Annual Production")

#remove objects
rm(tempx, tempy)

# Compute the correlation between the 2 series
cat("Corr(Price , Production): ", cor(price.ts,production.ts))

#Investigating the cointegrated model

# 1. Fit a linear regression model
GAS.lm <- lm(price.ts ~ production.ts)
summary(GAS.lm)
# The slop coefficient estimate is highly significant, but the overall model and the coefficient are not signficant. # The R-square is very low.

# 2. Obtain the residuals
GAS.res <- resid(GAS.lm)
summary(GAS.res)  
plot(GAS.res, xlab="t", ylab="Residuals", lty=1, pch=1, col="blue")
title("Residuals from the Linear Regression of Price to Production ")

par(mfrow=c(2,2))
plot(GAS.res, xlab="t", ylab="Residuals", lty=1, pch=1, col="blue"); title("Residuals of Price on Production")
plot(density(GAS.res), main="Kernel Density of Residuals")
acf(GAS.res, main="ACF of Residuals")
pacf(GAS.res, main="PACF of Residuals")

#Cross correlation Function between Price and Production
par(mfrow=c(1,1))
ccf(price.ts, production.ts, main="Cross-correlation between Price and Production")

# This shows that histogram and correlation may not be effective tools for time series data
pm = ggpairs(cbind(price.ts, production.ts))
print(pm)

#Fit an Autoregressive Model to both price and production series
GAS.ar <- ar(cbind(price.ts, production.ts), method="ols", dmean=T, intercept=F)
summary(GAS.ar) # Objects of the estimation results
GAS.ar$ar
GAS.ar$order
#==> it suggests that the best fitting VAR model is of order 26

# Diagnosis using the estimated residuals
dim(GAS.ar$res)
summary(GAS.ar$res)
GAS.ar$res #list the residual

ggpairs(GAS.ar$res) # the residuals do look "fairly" normal and
                   # not correlated with each other

ts.plot(GAS.ar$res[,1], GAS.ar$res[,2], gpars=list(xlab="Simulated Time Period", ylab="Series Values",      lty=c(1:2), pch=c(1,4), col=c("blue","black")))
title("Estimated Resduals from the VAR(26) Model")
leg.txt <- c('Price', 'Production')
legend('topleft', leg.txt, lty=1, col=c('blue', 'black'), bty='n', cex=.75)

#par(mfrow=c(2,2))
#  ts.plot(GAS.ar$res[-c(1:3),1], col="blue", main="Price Residuals from a VAR(26) Model")
#  ts.plot(GAS.ar$res[-c(1:3),2], col="black", main="Production Residuals from a VAR(26) Model")
#  acf(GAS.ar$res[-c(1:3),1], col="blue", main="ACF of Price Residuals")
#  acf(GAS.ar$res[-c(1:3),2], main="ACF of Production Residuals")

#Fit a Vector Vector AR Model
#GAS.var <- VAR(cbind(price.ts,production.ts), p=3, type="trend")
x <- cbind(price.ts,production.ts)
GAS.var <- VAR(x, p=1, type="trend")
summary(GAS.var)
coef(GAS.var)

# 24-Step ahead forecast or 1-year forecast
GAS.pred <- predict(GAS.var, n.ahead=24)
GAS.pred

price.pred <- ts(GAS.pred$fcst$price.ts[,1], st=c(2012,2,1), fr=12)
production.pred  <- ts(GAS.pred$fcst$production.ts[,1], st=c(2012,2,1), fr=12)

#Plot without CI info
ts.plot(cbind(window(price.ts, start=1978), price.pred), lty=1:2 )
ts.plot(cbind(window(production.ts, start=1978), production.pred), lty=1:2)

VARselect(x, lag.max=30, type="both")
summary(fit <- VAR(x, p=2, type="both"))

summary(VAR(x, p=1, type="both"))  # "both" fits constant + trend

#Run an Autocorrelation on the residuals
acf(resid(fit), 52)
serial.test(fit, lags.pt=12, type="PT.adjusted")

#Plot with 95% CI
fit.pr = predict(fit, n.ahead = 24, ci = 0.95)  # 2 years ahead
fanchart(fit.pr)  # plot prediction + error

```


Task 3: Compare the accuracy of the two models' forecasting results. Also, compare and contrast the results of these two models. Is one model better than the other? What metric(s) do you use to measure whether one model is "better" than the other? Why or why not? Explain the pros and cons of each of the models in this specific context.



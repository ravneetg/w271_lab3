---
title: "Applied Regression and Time Series Analysis: Lab 2"
author: "Jeffrey Yau and Devesh Tiwari"
date: "October 25, 2016"
output: pdf_document
---

##Instructions:

*  **Due Date: 12/16/2016 (Friday)**
*  Late submission will not receive any credit.
*  Instructions must be followed strictly.
*  This lab can be completed in a group of up to 3 people. Each group only needs to make one submission.
*  Submit 2 files: (1) a report (in pdf format) detailing your analyses; (2) your R script or juypter notebook supporting all of your answers. Missing one of this files will result in an automatic 50% reduction in score.
*  Use only techniques and R libraries that are covered in this course.
*  If you use R libraries and/or functions to conduct hypothesis tests not covered in this course, you will have to explain why the function you use is appropriate for the hypothesis you are asked to test
*  Thoroughly analyze the given dataset or data series. Detect any anomalies in each of the variables.
*  Your report needs to include a comprehensive graphical analysis
*  Your analysis needs to be accompanied by detailed narrative. Just printing a bunch of graphs and econometric results will likely receive a very low score.
*  Your analysis needs to show that your models are valid (in statistical sense).
*  Your rationale of using certian metrics to choose models need to be provided. Explain the validity / pros / cons of the metric you use to choose your "best" model.
*  Your rationale of any decisions made in your modeling needs to be explained and supported with empirical evidence.
*  All the steps to arrive at your final model need to be shown and explained clearly.
*  All of the assumptions of your final model need to be thoroughly tested, explained, and shown to be valid. Don't just write something like, *"the plot looks reasonable", or "the plot looks good*, as different people interpret vague terms like "reasonable" or "good" differently.
*  Students are expected to act with regards to UC Berkeley Academic Integrity.


# Forecast Inflation-Adjusted Gas Price
During 2013 amid high gas prices, the Associated Press (AP) published an article about the U.S. inflation-adjusted price of gasoline and U.S. oil production. The article claims that there is "*evidence of no statistical correlation*" between oil production and gas prices. The data was not made publicly available, but comparable data was created using data from the Energy Information Administration. The workspace and data frame *gasOil.Rdata* contains the U.S. oil production (in millions of barrels of oil) and the inflation-adjusted average gas prices (in dollars) over the date range the article indicates.

You have three tasks for this exericse, and both tasks need the use of the data set *gasOil.Rdata*.

```{r}
library(dtplyr)
library(Hmisc)
library(astsa)
library(stargazer)
library(forecast)
library(readr)
library(reshape2)
library(car)
library(vars)
library(tseries)
load("gasOil.Rdata")
```


Task 1: Create a **SARIMA-type** model to forecast the inflation-adjusted gas prices, and use this model to forecast the inflation-adjusted gas price for the next two years.

#Exploratory Data Analysis

The price series is not stationary, as the time series has strong persistency and inconsistent variation.  In particular, the time series before 2005 shows a strong persistence while the time series after 2005 shows much greater variation.  Also, ACF does not seem to drop off.  The PACF seems to drop off after 2 lags, and the second lag seems to have a negative coefficient.  There are no sudden spikes in either ACF or PACF that would suggest a seasonal effect.


```{r}
describe(gasOil)
 runEDA = function(x,label,l = 50){
   par(mfrow=c(3,1))
   print(paste("Dickey Fuller Test:",adf.test(x)$p.value)
         )
   plot.ts(x, main = paste("Time Series Plot of",label),ylab= label)
   acf(x,main = paste("ACFPlot of",label),ylab = label,lag.max = l)
   pacf(x, main = paste("PACF Plot of",label),ylab = label,lag.max=l)

 }
 runEDA(gasOil$Price,"Price")


```


So let's take the first difference and run EDA again.  The differenced series does not show persistency, but there is still increased variance after 2005.  This is unlikely to be fixed by taking more differences, because the ADF test says that the series does not have any roots greater than |1|.  So I'm going to start the model building process here.

Note that in the differenced series the ACF drops off after 1 lag, but seems to reappear approximately every 6 lags and then lingers for 1 or 2 lags before dropping again.  This suggests a MA component with degree 1 and a seasonal MA component with period 6 and degree 2.  In the PACF graph, the correlation drops off after 2 lags, but then reappears approximately every 5 lags.  This suggest an AR component with degree 2 and seasonal AR component with period 5 and degree 1.

```{r}
diffPrice = diff(gasOil$Price,differences = 1)
runEDA(diffPrice, "Change in Price")
```

#Model Training 

So the general ballpark is SARIMA model with order (2,1,1) and seasonal order (1,1,1~2) and period 5~6.  To nail down the exact parameters, we will need to use the AIC:

```{r}
runFitDiagnoseModel = function(x1,o,s,holdout=0){
# 7. Backtesting and Out-of-Sample Forecasting
# Re-estimate the model holding out 10 observations
    original =x1[1:(length(x1)-holdout)] 

  fit <- arima(original, order=o,seasonal = s)


# Model Diagnostics: Residuals
  print(Box.test(fit$resid, type="Ljung-Box"))

  par(mfrow=c(2,2))
  plot(fit$resid, col="blue", main="Residual Series")
  hist(fit$resid, col="gray", main="Residuals")
  acf(fit$resid , main="ACF: Residual Series")
  pacf(fit$resid,main="PACF: Residual Series")

# Model Performance Evaluation: In-Sample Fit

  df <- data.frame(cbind(original,fitted(fit),fit$resid ))
  stargazer(df, type="text", title="Descriptive Stat", digits=1)
##########

# Plot the original and estimate series 
  par(mfrow=c(1,1))
  plot.ts(original, col="navy", 
          main=paste("Original vs ARIMA(",toString(o),"),(",toString(s), ") with Resdiauls"),
          ylab="Original and Estimated Values",
          lty=2,ylim=c(0,4))
  lines(fitted(fit),col="blue",xlab="",ylab="")

  leg.txt <- c("Original", "Estimated", "Residuals")
  legend("bottomleft", legend=leg.txt, lty=c(2,1,1), col=c("navy","blue","green"),
         bty='n', cex=1)

  lines(fit$resid,xlab="",ylab="",col="green",
          pch=1)
  mtext("Residuals", side=4, line=2,col="green")
  #--------------------------------------
if(holdout > 0){
  fit.fcast <- forecast.Arima(fit, h=holdout)

  par(mfrow=c(1,1),new=F)
  plot(fit.fcast,lty=0,
       main="Out-of-Sample Forecast",
     
       ylab="Original, Estimated, and Forecast Values")
  lines(fitted(fit), col="blue")
  lines(x1, col="navy", lty=2)
  leg.txt <- c("Original", "Fitted", "Forecast")
  legend("bottomleft", legend=leg.txt, lty=c(2,1,1),
         col=c("navy","blue","blue"), lwd=c(1,1,2),
         bty='n', cex=1)
  MSE = mean((fit.fcast$mean - tail(x1,holdout))^2)
  print(paste("MSE:",MSE))
}
return(fit)
}
```


Out of the four possible models, model2 [ARIMA (2,1,1),(1,1,1) period 6] has the lowest mean squared error using a holdout of 24.  Also, model1 [ARIMA (2,1,1),(1,1,1) period 5] has a lower AIC than model3 [ARIMA (2,1,1),(1,1,2) period 5].  Model4 [ARIMA (2,1,1),(1,1,2) period 6] returned an error and would not compile.

```{r}
model1=runFitDiagnoseModel(gasOil$Price,c(2,1,1),list(order = c(1,1,1), period=5),24)
```
```{r}
model2=runFitDiagnoseModel(gasOil$Price,c(2,1,1),list(order = c(1,1,1), period=6),24)

```

```{r}
model3=runFitDiagnoseModel(gasOil$Price,c(2,1,1),list(order = c(1,1,2), period=5),24)

```

Model 4 (SARIMA (2,1,1),(1,1,2) period 6) returned an error.  

```{r}
print(try({
model4=runFitDiagnoseModel(gasOil$Price,c(2,1,1),list(order = c(1,1,2), period=6),24)},silent=T
))
```

Further diagnostics show that the 2nd AR and first MA coefficients in non-seasonal component of model2 are not siginificantly different from 0.  This suggests trying to fit an ARIMA (1,1,0), (1,1,1) period 6 model.

```{r}
t( confint(model2) )

```
While the new model5 [ARIMA (1,1,0),(1,1,1)] has some improvment in the MSE, its AIC is higher than model2.  So we're going to stick with model2 for now.

```{r}
model5=runFitDiagnoseModel(gasOil$Price,c(1,1,0),list(order = c(1,1,1), period=6),24)
AIC(model2,model5)
```

The last step is to retrain the model on the entire data set and then forecast 2 years out.  

```{r}
modelSarima=runFitDiagnoseModel(gasOil$Price,c(2,1,1),list(order = c(1,1,1), period=6))
forecastSarima = forecast.Arima(modelSarima, h=24)
print(forecastSarima)

```


Task 2: Create a *multivariate* time series model that can be used to predict/forecast inflation-adjusted gas prices, and use this model to forecast the inflation-adjusted gas price for the next two years



Task 3: Compare the accuracy of the two models' forecasting results. Also, compare and contrast the results of these two models. Is one model better than the other? What metric(s) do you use to measure whether one model is "better" than the other? Why or why not? Explain the pros and cons of each of the models in this specific context.


